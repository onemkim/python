Reference:
- https://medium.com/@tapanbabbar/how-to-run-llama-3-2-vision-on-ollama-a-game-changer-for-edge-ai-80cb0e8d8928
- https://pub.towardsai.net/enhance-ocr-with-llama-3-2-vision-using-ollama-0b15c7b8905c
- https://github.com/ollama/ollama/releases
- https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/

Source code: https://github.com/tapanBabbar9/computer-vision/blob/main/book-cover/book-cover-llama3.2-vision.ipynb


# From Good to Great: Enter Llama 3.2-Vision
Llama 3.2-Vision has supercharged the OCR + information extraction pipeline. The new ‘vision’ support makes it smarter, faster, and more efficient than the previous versions. Llama 3.1 handled cleaning up raw OCR output, but Llama 3.2-Vision does that and more — processing the images directly with less hassle, cutting down the need for third-party OCR tools like EasyOCR. It integrates everything into one simple, streamlined process.

This simplifies the workflow and boosts accuracy since Llama 3.2-Vision performs the entire task in one go: analyzing the image, detecting text, and structuring it based on your requirements.

